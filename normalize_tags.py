#!/usr/bin/env python3
"""
Normaliza etiquetas: singulariza plurales, elimina duplicados sem√°nticos
Autor: Claude Code
Fecha: 2025-11-15
"""

import csv
import re
from collections import Counter

INPUT_FILE = "palabras_ponencias_filtradas.csv"
OUTPUT_FILE = "palabras_ponencias_normalizadas.csv"
STATS_FILE = "normalizacion_estadisticas.txt"

def singularize(word):
    """
    Convierte plurales a singular en espa√±ol (reglas b√°sicas)
    """
    word_lower = word.lower()

    # Lista de verbos conjugados y formas verbales (NO singularizar)
    verb_forms = ['amos', 'emos', 'imos', 'amos', '√©is', '√°is', '√≠s']
    for ending in verb_forms:
        if word_lower.endswith(ending):
            return word_lower  # No modificar formas verbales

    # Excepciones: palabras invariables o singulares que parecen plurales
    invariant_words = {
        'antes', 'viernes', 'lunes', 'martes', 'mi√©rcoles', 'jueves',
        'mes', 'despu√©s', 'inter√©s', 'estr√©s', 'cipr√©s', 'an√°lisis',
        'm√°s', 'atr√°s', 'dem√°s', 'gas', 'comp√°s', 'crisis', 'tesis',
        'osis', 'dosis', 'osis', 'gratis', 'tras', 'ambos'
    }
    if word_lower in invariant_words:
        return word_lower

    # Regla 1: Palabras que terminan en -ces ‚Üí -z (ej: luces ‚Üí luz)
    if word_lower.endswith('ces') and len(word_lower) > 4:
        return word_lower[:-3] + 'z'

    # Regla 2: Palabras que terminan en -iones ‚Üí -i√≥n (ej: acciones ‚Üí acci√≥n)
    if word_lower.endswith('iones') and len(word_lower) > 5:
        return word_lower[:-2]

    # Regla 3: Palabras que terminan en -aciones, -iciones ‚Üí -aci√≥n, -ici√≥n
    if word_lower.endswith('ciones') and len(word_lower) > 6:
        return word_lower[:-2]

    # Regla 4: Palabras que terminan en -ses ‚Üí -s (ej: an√°lisis ‚Üí an√°lisis)
    if word_lower.endswith('ses') and len(word_lower) > 4:
        return word_lower[:-2]

    # Regla 5: Palabras que terminan en -les, -res, -nes ‚Üí -l, -r, -n (ej: digitales ‚Üí digital)
    if word_lower.endswith('les') and len(word_lower) > 4:
        return word_lower[:-2]
    if word_lower.endswith('res') and len(word_lower) > 4:
        return word_lower[:-2]
    if word_lower.endswith('nes') and len(word_lower) > 4:
        return word_lower[:-2]

    # Regla 6: Palabras que terminan en -es (plurales de consonante)
    if word_lower.endswith('es') and len(word_lower) > 3:
        # Si termina en consonante + es, quitar solo -s
        if word_lower[-3] in 'bcdfghjklmnpqrstvwxyz√±':
            return word_lower[:-1]

    # Regla 7: Palabras que terminan en -os ‚Üí -o (ej: datos ‚Üí dato)
    if word_lower.endswith('os') and len(word_lower) > 3:
        # Excepciones: palabras que ya son singulares
        if word_lower not in ['dios', 'tos', 'dos', 'ambos']:
            return word_lower[:-1]

    # Regla 8: Palabras que terminan en -as ‚Üí -a (ej: empresas ‚Üí empresa)
    if word_lower.endswith('as') and len(word_lower) > 3:
        return word_lower[:-1]

    # Si no coincide con ninguna regla, devolver la palabra original
    return word_lower

def main():
    print("=" * 70)
    print("üîÑ NORMALIZACI√ìN DE ETIQUETAS (SINGULAR)")
    print("=" * 70)
    print(f"üìÅ Entrada: {INPUT_FILE}")
    print(f"üìÅ Salida: {OUTPUT_FILE}")
    print("-" * 70)

    # Leer etiquetas filtradas
    tags = []
    try:
        with open(INPUT_FILE, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                tags.append(row['nombre_etiqueta'].strip())
    except FileNotFoundError:
        print(f"‚ùå Error: No se encontr√≥ {INPUT_FILE}")
        return

    print(f"‚úÖ Le√≠das {len(tags)} etiquetas filtradas")

    # Normalizar a singular
    normalized_tags = {}  # {singular: [plural1, plural2, ...]}

    for tag in tags:
        singular = singularize(tag)
        if singular not in normalized_tags:
            normalized_tags[singular] = []
        if tag != singular:
            normalized_tags[singular].append(tag)

    # Contar conversiones
    plurals_converted = sum(len(plurals) for plurals in normalized_tags.values() if plurals)

    print(f"‚úÖ Etiquetas √∫nicas (singular): {len(normalized_tags)}")
    print(f"üîÑ Plurales convertidos: {plurals_converted}")
    print(f"üìâ Reducci√≥n: {len(tags)} ‚Üí {len(normalized_tags)} ({len(tags) - len(normalized_tags)} eliminados)")

    # Escribir CSV normalizado
    print("-" * 70)
    print(f"üíæ Escribiendo {OUTPUT_FILE}...")

    with open(OUTPUT_FILE, 'w', encoding='utf-8', newline='') as f:
        writer = csv.DictWriter(f, fieldnames=['id', 'nombre_etiqueta', 'source'])
        writer.writeheader()

        for idx, tag in enumerate(sorted(normalized_tags.keys()), start=1):
            writer.writerow({
                'id': idx,
                'nombre_etiqueta': tag,
                'source': 'ponencias'
            })

    print(f"‚úÖ Archivo normalizado creado: {OUTPUT_FILE}")

    # Generar estad√≠sticas
    print("-" * 70)
    print(f"üìä Generando estad√≠sticas: {STATS_FILE}...")

    # Encontrar casos con m√∫ltiples plurales
    multiple_plurals = {s: p for s, p in normalized_tags.items() if len(p) > 1}

    with open(STATS_FILE, 'w', encoding='utf-8') as f:
        f.write("=" * 70 + "\n")
        f.write("ESTAD√çSTICAS DE NORMALIZACI√ìN (SINGULAR)\n")
        f.write("=" * 70 + "\n\n")

        f.write("üìä RESUMEN\n")
        f.write(f"   Etiquetas filtradas originales: {len(tags)}\n")
        f.write(f"   Etiquetas normalizadas (√∫nicas): {len(normalized_tags)}\n")
        f.write(f"   Plurales convertidos a singular: {plurals_converted}\n")
        f.write(f"   Reducci√≥n total: {len(tags) - len(normalized_tags)} etiquetas\n")
        f.write(f"   Tasa de reducci√≥n: {(len(tags) - len(normalized_tags))/len(tags)*100:.1f}%\n\n")

        # Casos con m√∫ltiples plurales
        if multiple_plurals:
            f.write(f"üîÄ CASOS CON M√öLTIPLES FORMAS PLURALES (top 30)\n")
            f.write("-" * 70 + "\n")
            sorted_multiples = sorted(multiple_plurals.items(),
                                     key=lambda x: len(x[1]),
                                     reverse=True)[:30]
            for singular, plurals in sorted_multiples:
                f.write(f"   {singular:20s} ‚Üê {', '.join(plurals)}\n")
            f.write("\n")

        # Ejemplos de conversiones
        f.write("üìù EJEMPLOS DE CONVERSIONES (50 primeros)\n")
        f.write("-" * 70 + "\n")
        conversions = [(s, p) for s, p in normalized_tags.items() if p][:50]
        for singular, plurals in sorted(conversions):
            plural_str = ', '.join(plurals)
            f.write(f"   {plural_str:30s} ‚Üí {singular}\n")

        # Muestra de etiquetas finales
        f.write("\n‚úÖ MUESTRA DE 100 ETIQUETAS FINALES (alfab√©tico)\n")
        f.write("-" * 70 + "\n")
        for idx, tag in enumerate(sorted(normalized_tags.keys())[:100], start=1):
            f.write(f"   {idx:3d}. {tag}\n")

    print(f"‚úÖ Estad√≠sticas guardadas: {STATS_FILE}")

    # Mostrar muestra
    print("-" * 70)
    print("üìù EJEMPLOS DE CONVERSIONES PLURAL ‚Üí SINGULAR:")
    conversions = [(s, p) for s, p in normalized_tags.items() if p][:20]
    for singular, plurals in sorted(conversions):
        print(f"   {', '.join(plurals):30s} ‚Üí {singular}")

    print("-" * 70)
    print("‚úÖ MUESTRA DE 30 ETIQUETAS FINALES (alfab√©tico):")
    for idx, tag in enumerate(sorted(normalized_tags.keys())[:30], start=1):
        print(f"   {idx:2d}. {tag}")

    print("-" * 70)
    print("üéâ NORMALIZACI√ìN COMPLETADA")
    print(f"   üìù Etiquetas finales: {len(normalized_tags)}")
    print(f"   üìÅ Archivo: {OUTPUT_FILE}")
    print(f"   üìä Estad√≠sticas: {STATS_FILE}")
    print("=" * 70)

if __name__ == "__main__":
    main()
