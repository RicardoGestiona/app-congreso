#!/usr/bin/env python3
"""
Filtra palabras irrelevantes PERO mantiene las repeticiones para frecuencias
Autor: Claude Code
Fecha: 2025-11-15
"""

import csv
import re
from collections import Counter

INPUT_FILE = "palabras_ponencias.csv"
OUTPUT_FILE = "palabras_ponencias_con_frecuencias.csv"
STATS_FILE = "frecuencias_estadisticas.txt"

# Copiar las mismas stopwords y listas de filtrado
STOPWORDS = {
    # Art√≠culos
    'el', 'la', 'los', 'las', 'un', 'una', 'unos', 'unas',
    # Preposiciones (incluyendo contracciones)
    'a', 'ante', 'bajo', 'con', 'contra', 'de', 'del', 'desde', 'en', 'entre', 'hacia',
    'hasta', 'para', 'por', 'seg√∫n', 'sin', 'sobre', 'tras', 'durante', 'mediante', 'al',
    # Pronombres
    'yo', 't√∫', '√©l', 'ella', 'nosotros', 'nosotras', 'vosotros', 'vosotras',
    'ellos', 'ellas', 'me', 'te', 'se', 'nos', 'os', 'lo', 'la', 'los', 'las',
    'le', 'les', 'mi', 'tu', 'su', 'nuestro', 'vuestro', 'm√≠o', 'tuyo', 'suyo',
    'este', 'ese', 'aquel', 'esta', 'esa', 'aquella', 'esto', 'eso', 'aquello',
    'estos', 'esos', 'aquellos', 'estas', 'esas', 'aquellas',
    # Conjunciones
    'y', 'e', 'o', 'u', 'pero', 'sino', 'que', 'porque', 'pues', 'como',
    'si', 'aunque', 'cuando', 'mientras', 'donde',
    # Adverbios comunes
    'no', 's√≠', 'tambi√©n', 'tampoco', 'muy', 'm√°s', 'menos', 'poco', 'mucho',
    'tanto', 'tan', 'casi', 'solo', 'solamente', 'ahora', 'aqu√≠', 'ah√≠', 'all√≠',
    'siempre', 'nunca', 'jam√°s', 'todav√≠a', 'a√∫n', 'ya', 'antes', 'despu√©s',
    'luego', 'entonces', 'as√≠', 'bien', 'mal', 'mejor', 'peor', 'adem√°s', 'incluso',
    # Interrogativos
    'qu√©', 'qui√©n', 'qui√©nes', 'cu√°l', 'cu√°les', 'cu√°ndo', 'c√≥mo', 'd√≥nde', 'cu√°nto', 'cu√°nta',
    # Verbos auxiliares y muy comunes
    'ser', 'estar', 'haber', 'tener', 'hacer', 'ir', 'poder', 'decir', 'dar',
    'saber', 'querer', 'ver', 'poner', 'venir', 'llevar', 'pasar', 'deber',
    'es', 'est√°', 'son', 'est√°n', 'hay', 'he', 'ha', 'han', 'hemos', 'hab√©is',
    'tengo', 'tiene', 'tienen', 'tenemos', 'ten√©is', 'hago', 'hace', 'hacen', 'voy', 'va', 'van',
    'vamos', 'vais', 'puedo', 'puede', 'pueden', 'digo', 'dice', 'dicen',
    'soy', 'eres', 'somos', 'sois', 'era', 'eras', '√©ramos', 'erais', 'eran',
    'fui', 'fue', 'fueron', 'sido', 'siendo', 'sea', 'seas', 'seamos', 'se√°is', 'sean',
    'estoy', 'est√°s', 'estamos', 'est√°is', 'estaba', 'estabas', 'est√°bamos', 'estaban',
    # Verbos comunes conjugados (a√±adidos)
    'creo', 'creer', 'crees', 'cree', 'creemos', 'creen', 'cre√≠a', 'cre√≠an',
    'hab√≠a', 'hab√≠an', 'hab√≠as', 'hab√≠amos', 'habr√≠a', 'habr√≠an', 'habr√°',
    'digo', 'dice', 'decir', 'dije', 'dijo', 'dijeron', 'dicho', 'diciendo',
    'puedes', 'podemos', 'pod√©is', 'pod√≠a', 'pod√≠an', 'podr√≠a', 'podr√≠an', 'podr√°',
    'ten√≠a', 'ten√≠an', 'ten√≠as', 'ten√≠amos', 'tendr√≠a', 'tendr√≠an', 'tendr√°',
    # Determinantes
    'todo', 'todos', 'toda', 'todas', 'mismo', 'misma', 'mismos', 'mismas',
    'otro', 'otra', 'otros', 'otras', 'uno', 'una', 'unos', 'unas',
    'alguno', 'alguna', 'algunos', 'algunas', 'ninguno', 'ninguna',
    'cada', 'varios', 'varias', 'ambos', 'ambas', 'cualquier', 'cualquiera',
    'muchos', 'muchas', 'pocos', 'pocas',
    # Palabras de relleno
    'cosa', 'cosas', 'algo', 'nada', 'alguien', 'nadie', 'vez', 'veces',
    'vale', 'bueno', 'pues', 'claro', 'gracias', 'hola', 'adi√≥s',
}

GENERIC_WORDS = {
    # Temporales
    'a√±o', 'a√±os', 'd√≠a', 'd√≠as', 'mes', 'meses', 'semana', 'semanas',
    'hora', 'horas', 'minuto', 'minutos', 'segundo', 'segundos',
    'vez', 'veces', 'momento', 'momentos', 'tiempo', 'tiempos',
    'hoy', 'ayer', 'ma√±ana', 'tarde', 'noche',
    # Espaciales
    'parte', 'partes', 'lugar', 'lugares', 'lado', 'lados', 'sitio', 'sitios',
    'dentro', 'fuera', 'arriba', 'abajo', 'encima', 'debajo', 'cerca', 'lejos',
    # Abstractos gen√©ricos
    'tipo', 'tipos', 'forma', 'formas', 'manera', 'maneras',
    'caso', 'casos', 'tema', 'temas', 'punto', 'puntos', 'aspecto', 'aspectos',
    'gente', 'persona', 'personas', 'mundo',
    'ejemplo', 'ejemplos', 'hecho', 'hechos', 'verdad',
    # Ordinales y cardinales comunes
    'uno', 'dos', 'tres', 'cuatro', 'cinco', 'seis', 'siete', 'ocho', 'nueve', 'diez',
    'primero', 'primera', 'segundo', 'segunda', 'tercero', 'tercera',
    '√∫ltimo', '√∫ltima', '√∫ltimos', '√∫ltimas', '√∫nico', '√∫nica',
    # Adjetivos gen√©ricos
    'bueno', 'buena', 'buenos', 'buenas', 'malo', 'mala', 'malos', 'malas',
    'grande', 'grandes', 'peque√±o', 'peque√±a', 'nuevo', 'nueva', 'nuevos', 'nuevas',
    'viejo', 'vieja', 'viejos', 'viejas', 'final', 'finales',
    'cierto', 'cierta', 'ciertos', 'ciertas', 'principal', 'principales',
    'importante', 'importantes', 'necesario', 'necesaria', 'necesarios', 'necesarias',
    # Verbos comunes que se colaron
    'dec√≠a', 'dec√≠an', 'dice', 'dicen', 'dije', 'dijo', 'dijeron',
    'vais', 'queda', 'quedan', 'parece', 'parecen', 'parecer',
    'imaginar', 'veros', 'ubicando', 'mola', 'chulada',
    'bonita', 'bonito', 'bonitos', 'bonitas', 'desaqu√≠', 'promociones',
}

TECHNICAL_ACRONYMS = {
    'ia', 'ai', 'api', 'sql', 'css', 'html', 'xml', 'json', 'http', 'https',
    'www', 'url', 'uri', 'pdf', 'csv', 'rpa', 'erp', 'crm', 'bi', 'ti', 'tic',
    'app', 'web', 'ssl', 'tls', 'dns', 'vpn', 'lan', 'wan', 'ip', 'tcp',
    'udp', 'ftp', 'ssh', 'gui', 'cli', 'sdk', 'ide', 'cms', 'seo', 'sem',
}

def is_valid_tag(word):
    """Determina si una palabra es v√°lida"""
    word_lower = word.lower().strip()

    if not word_lower:
        return False
    if word_lower in TECHNICAL_ACRONYMS:
        return True
    if word_lower in STOPWORDS:
        return False
    if word_lower in GENERIC_WORDS:
        return False
    if len(word_lower) < 3:
        return False
    if word_lower.isdigit():
        return False
    if not re.match(r'^[a-z√°√©√≠√≥√∫√º√±0-9\-]+$', word_lower):
        return False

    return True

def main():
    print("=" * 70)
    print("üîç FILTRADO MANTENIENDO FRECUENCIAS")
    print("=" * 70)
    print(f"üìÅ Entrada: {INPUT_FILE}")
    print(f"üìÅ Salida: {OUTPUT_FILE}")
    print("-" * 70)

    # Leer TODAS las filas del CSV original
    all_tags = []
    try:
        with open(INPUT_FILE, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                all_tags.append(row['nombre_etiqueta'].strip())
    except FileNotFoundError:
        print(f"‚ùå Error: No se encontr√≥ {INPUT_FILE}")
        return

    print(f"‚úÖ Le√≠das {len(all_tags)} etiquetas originales (con repeticiones)")

    # Filtrar pero MANTENER repeticiones
    valid_tags = []
    filtered_count = 0

    for tag in all_tags:
        if is_valid_tag(tag):
            valid_tags.append(tag.lower())
        else:
            filtered_count += 1

    print(f"‚úÖ Etiquetas v√°lidas: {len(valid_tags)} (con repeticiones)")
    print(f"‚ùå Etiquetas filtradas: {filtered_count}")

    # Contar frecuencias
    freq = Counter(valid_tags)
    print(f"üìä Etiquetas √∫nicas: {len(freq)}")
    print(f"üîÑ Total de ocurrencias: {len(valid_tags)}")
    print(f"üìà Promedio de repeticiones: {len(valid_tags)/len(freq):.1f}")

    # Escribir CSV con todas las ocurrencias
    print("-" * 70)
    print(f"üíæ Escribiendo {OUTPUT_FILE}...")

    with open(OUTPUT_FILE, 'w', encoding='utf-8', newline='') as f:
        writer = csv.DictWriter(f, fieldnames=['id', 'nombre_etiqueta', 'source'])
        writer.writeheader()

        for idx, tag in enumerate(valid_tags, start=1):
            writer.writerow({
                'id': idx,
                'nombre_etiqueta': tag,
                'source': 'ponencias'
            })

    print(f"‚úÖ Archivo creado: {OUTPUT_FILE}")
    print(f"   Total de filas: {len(valid_tags)}")

    # Generar estad√≠sticas
    print("-" * 70)
    print(f"üìä Generando estad√≠sticas: {STATS_FILE}...")

    with open(STATS_FILE, 'w', encoding='utf-8') as f:
        f.write("=" * 70 + "\n")
        f.write("ESTAD√çSTICAS DE FRECUENCIAS\n")
        f.write("=" * 70 + "\n\n")

        f.write("üìä RESUMEN\n")
        f.write(f"   Etiquetas originales (total): {len(all_tags)}\n")
        f.write(f"   Etiquetas filtradas: {filtered_count}\n")
        f.write(f"   Etiquetas v√°lidas (total): {len(valid_tags)}\n")
        f.write(f"   Etiquetas √∫nicas: {len(freq)}\n")
        f.write(f"   Promedio repeticiones: {len(valid_tags)/len(freq):.1f}\n\n")

        f.write("üîù TOP 100 ETIQUETAS M√ÅS FRECUENTES\n")
        f.write("-" * 70 + "\n")
        for idx, (word, count) in enumerate(freq.most_common(100), start=1):
            f.write(f"   {idx:3d}. {word:30s} : {count:5d} veces\n")

        f.write("\nüìâ DISTRIBUCI√ìN DE FRECUENCIAS\n")
        f.write("-" * 70 + "\n")
        freq_dist = Counter(freq.values())
        f.write(f"   Palabras que aparecen 1 vez:    {freq_dist[1]:5d}\n")
        f.write(f"   Palabras que aparecen 2-5 veces: {sum(freq_dist[i] for i in range(2,6)):5d}\n")
        f.write(f"   Palabras que aparecen 6-10 veces: {sum(freq_dist[i] for i in range(6,11)):5d}\n")
        f.write(f"   Palabras que aparecen 11-20 veces: {sum(freq_dist[i] for i in range(11,21)):5d}\n")
        f.write(f"   Palabras que aparecen >20 veces: {sum(freq_dist[i] for i in range(21,1000)):5d}\n")

    print(f"‚úÖ Estad√≠sticas guardadas: {STATS_FILE}")

    # Mostrar top 20
    print("-" * 70)
    print("üîù TOP 20 ETIQUETAS M√ÅS FRECUENTES:")
    for idx, (word, count) in enumerate(freq.most_common(20), start=1):
        print(f"   {idx:2d}. {word:30s} : {count:5d} veces")

    print("-" * 70)
    print("üéâ PROCESO COMPLETADO")
    print(f"   üìù Total ocurrencias: {len(valid_tags)}")
    print(f"   üìä Etiquetas √∫nicas: {len(freq)}")
    print(f"   üìÅ Archivo: {OUTPUT_FILE}")
    print("=" * 70)

if __name__ == "__main__":
    main()
